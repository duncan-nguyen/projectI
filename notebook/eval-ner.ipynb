{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-21T09:17:51.175755Z",
     "iopub.status.busy": "2025-12-21T09:17:51.175579Z",
     "iopub.status.idle": "2025-12-21T09:19:26.573838Z",
     "shell.execute_reply": "2025-12-21T09:19:26.573011Z",
     "shell.execute_reply.started": "2025-12-21T09:17:51.175739Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install gliner protobuf==3.20.3\n",
    "!pip install accelerate\n",
    "!pip install --upgrade transformers accelerate\n",
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-21T09:19:26.575832Z",
     "iopub.status.busy": "2025-12-21T09:19:26.574960Z",
     "iopub.status.idle": "2025-12-21T09:19:37.970862Z",
     "shell.execute_reply": "2025-12-21T09:19:37.970140Z",
     "shell.execute_reply.started": "2025-12-21T09:19:26.575800Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1915b53de6c949a88a9fd817c1e2d7e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/437 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226eecf2236841f29dba13c6210876f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/16.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdaf7fbe386a485193bb87f6109fec3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"nqdhocai/ner-covid19-test\")\n",
    "test_data = dataset['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval GLINER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-21T09:19:37.994682Z",
     "iopub.status.busy": "2025-12-21T09:19:37.994426Z",
     "iopub.status.idle": "2025-12-21T09:20:29.529860Z",
     "shell.execute_reply": "2025-12-21T09:20:29.529222Z",
     "shell.execute_reply.started": "2025-12-21T09:19:37.994661Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-21 09:19:45.414004: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1766308785.588241      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1766308785.635087      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1e41242ea84015ad3450ceac6703dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e765f4657894ceb9fb7263392c2e8f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gliner_config.json:   0%|          | 0.00/477 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c90892c63846ebbeb9c7b7eb8bad9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e10f79f02940c39806f7f9736d6b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf6e740537e403db963e7c396a639b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.16G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972a9e81547c4b749dacc3995671a5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.16G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e429f6502998479c898be674868e8cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b05f78ea2404b48ad869c65ebf09596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670fbed55fc34adf82ae789242e981ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "üöÄ GLiNER inference:   0%|          | 0/3 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "üöÄ GLiNER inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:02<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìä TOKEN-LEVEL CLASSIFICATION REPORT (clean labels, O removed)\n",
      "======================================================================\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                AGE     0.5222    0.8393    0.6438        56\n",
      "               DATE     0.8333    0.9223    0.8756       103\n",
      "             GENDER     0.8214    0.7931    0.8070        29\n",
      "                JOB     0.9455    0.2241    0.3624       232\n",
      "           LOCATION     0.9229    0.5870    0.7176       632\n",
      "               NAME     0.7349    0.8551    0.7905       214\n",
      "       ORGANIZATION     0.4569    0.8971    0.6055       136\n",
      "         PATIENT_ID     0.5854    0.4848    0.5304        99\n",
      "SYMPTOM_AND_DISEASE     0.9444    0.6733    0.7861       101\n",
      "     TRANSPORTATION     0.8543    0.5890    0.6973       219\n",
      "\n",
      "          micro avg     0.7536    0.6249    0.6833      1821\n",
      "          macro avg     0.7621    0.6865    0.6816      1821\n",
      "       weighted avg     0.8245    0.6249    0.6718      1821\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üìä ENTITY-LEVEL REPORT (seqeval, BIO)\n",
      "======================================================================\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                AGE     0.0455    0.0417    0.0435        48\n",
      "               DATE     0.6111    0.6875    0.6471        32\n",
      "             GENDER     0.8519    0.7931    0.8214        29\n",
      "                JOB     0.8696    0.2439    0.3810        82\n",
      "           LOCATION     0.5306    0.5200    0.5253       150\n",
      "               NAME     0.3837    0.5077    0.4371        65\n",
      "       ORGANIZATION     0.4429    0.8857    0.5905        35\n",
      "         PATIENT_ID     0.7083    0.3505    0.4690        97\n",
      "SYMPTOM_AND_DISEASE     0.8333    0.5208    0.6410        48\n",
      "     TRANSPORTATION     0.5593    0.4714    0.5116        70\n",
      "\n",
      "          micro avg     0.5281    0.4588    0.4910       656\n",
      "          macro avg     0.5836    0.5022    0.5067       656\n",
      "       weighted avg     0.5879    0.4588    0.4844       656\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üß© ERROR ANALYSIS ‚Äî Top Confusion Pairs (true ‚Üí pred)\n",
      "======================================================================\n",
      "               true                pred  count\n",
      "                JOB                   O    151\n",
      "           LOCATION        ORGANIZATION    137\n",
      "           LOCATION                   O    122\n",
      "     TRANSPORTATION                   O     64\n",
      "                  O                 AGE     41\n",
      "SYMPTOM_AND_DISEASE                   O     33\n",
      "                  O          PATIENT_ID     28\n",
      "     TRANSPORTATION            LOCATION     26\n",
      "                  O                NAME     26\n",
      "               NAME                   O     25\n",
      "         PATIENT_ID                   O     23\n",
      "         PATIENT_ID                NAME     20\n",
      "                JOB                NAME     18\n",
      "                  O                DATE     14\n",
      "       ORGANIZATION                   O     10\n",
      "                  O      TRANSPORTATION     10\n",
      "               DATE                   O      8\n",
      "               NAME          PATIENT_ID      6\n",
      "                JOB      TRANSPORTATION      6\n",
      "                AGE                DATE      5\n",
      "                  O        ORGANIZATION      4\n",
      "       ORGANIZATION      TRANSPORTATION      4\n",
      "                  O SYMPTOM_AND_DISEASE      4\n",
      "             GENDER                   O      4\n",
      "                AGE                   O      4\n",
      "\n",
      "======================================================================\n",
      "üß© ERROR ANALYSIS ‚Äî Error Type Distribution\n",
      "======================================================================\n",
      "                      error_type  count\n",
      "                        FN_other    264\n",
      "     FN_boundary_or_segmentation    170\n",
      "         Confusion_LOC_ORG_TRANS    163\n",
      "                        FP_other    131\n",
      "                 Confusion_other     76\n",
      "FN_normalization_disease_variant      5\n",
      "                  FN_format_DATE      5\n",
      "             FP_id_or_plate_like      2\n",
      "\n",
      "======================================================================\n",
      "üß© ERROR ANALYSIS ‚Äî False Negatives by Label (missed entities)\n",
      "======================================================================\n",
      "              label  FN_count\n",
      "                JOB       151\n",
      "           LOCATION       122\n",
      "     TRANSPORTATION        64\n",
      "SYMPTOM_AND_DISEASE        33\n",
      "               NAME        25\n",
      "         PATIENT_ID        23\n",
      "       ORGANIZATION        10\n",
      "               DATE         8\n",
      "             GENDER         4\n",
      "                AGE         4\n",
      "\n",
      "======================================================================\n",
      "üß© ERROR ANALYSIS ‚Äî False Positives by Label (spurious entities)\n",
      "======================================================================\n",
      "              label  FP_count\n",
      "                AGE        41\n",
      "         PATIENT_ID        28\n",
      "               NAME        26\n",
      "               DATE        14\n",
      "     TRANSPORTATION        10\n",
      "SYMPTOM_AND_DISEASE         4\n",
      "           LOCATION         4\n",
      "       ORGANIZATION         4\n",
      "             GENDER         2\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from gliner import GLiNER\n",
    "\n",
    "from seqeval.metrics import classification_report as seqeval_report\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# CONFIG\n",
    "# =========================================================\n",
    "BATCH_SIZE = 64\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "TARGET_LABELS = [\n",
    "    \"PATIENT_ID\", \"NAME\", \"AGE\", \"GENDER\", \"JOB\",\n",
    "    \"LOCATION\", \"ORGANIZATION\", \"SYMPTOM_AND_DISEASE\", \"TRANSPORTATION\", \"DATE\"\n",
    "]\n",
    "\n",
    "MODEL_PATH = \"urchade/gliner_multi-v2.1\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = GLiNER.from_pretrained(MODEL_PATH).to(DEVICE)\n",
    "\n",
    "# =========================================================\n",
    "# TAG CLEANING (BIO -> clean label) + alignment util\n",
    "# =========================================================\n",
    "def clean_original_tags(tags, id2label=None):\n",
    "    \"\"\"\n",
    "    tags: list[str] BIO ho·∫∑c list[int]\n",
    "    Return: list[str] clean label (b·ªè B-/I-), ch·ªâ c√≤n {O, LOCATION, ...}\n",
    "    \"\"\"\n",
    "    if len(tags) == 0:\n",
    "        return []\n",
    "\n",
    "    if not isinstance(tags[0], str):\n",
    "        if id2label is None:\n",
    "            raise ValueError(\"tags l√† s·ªë nh∆∞ng b·∫°n ch∆∞a cung c·∫•p id2label.\")\n",
    "        tags = [id2label[int(t)] for t in tags]\n",
    "\n",
    "    cleaned = []\n",
    "    for tag in tags:\n",
    "        if tag == \"O\" or tag is None:\n",
    "            cleaned.append(\"O\")\n",
    "            continue\n",
    "        if \"-\" in tag:\n",
    "            _, lb = tag.split(\"-\", 1)\n",
    "        else:\n",
    "            lb = tag\n",
    "\n",
    "        if lb in TARGET_LABELS:\n",
    "            cleaned.append(lb)\n",
    "        else:\n",
    "            cleaned.append(\"O\")\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def spans_to_token_tags(tokens, pred_spans, target_labels):\n",
    "    \"\"\"\n",
    "    Map span-level prediction -> token-level clean tags.\n",
    "    tokens: list[str]\n",
    "    pred_spans: list[dict] with keys: start, end, label (char offsets on full text)\n",
    "    \"\"\"\n",
    "\n",
    "    token_maps = []\n",
    "    cur = 0\n",
    "    for tok in tokens:\n",
    "        s = cur\n",
    "        e = s + len(tok)\n",
    "        token_maps.append((s, e))\n",
    "        cur = e + 1  \n",
    "\n",
    "    out = [\"O\"] * len(tokens)\n",
    "    for sp in pred_spans:\n",
    "        lb = sp.get(\"label\")\n",
    "        if lb not in target_labels:\n",
    "            continue\n",
    "        ps, pe = int(sp[\"start\"]), int(sp[\"end\"])\n",
    "\n",
    "        for i, (ts, te) in enumerate(token_maps):\n",
    "            if max(ts, ps) < min(te, pe):\n",
    "                out[i] = lb\n",
    "    return out\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# BIO -> spans (entity-level gold) ƒë·ªÉ l√†m entity-level eval\n",
    "# =========================================================\n",
    "def bio_to_spans(tokens, bio_tags):\n",
    "    \"\"\"\n",
    "    tokens: list[str]\n",
    "    bio_tags: list[str] d·∫°ng BIO (B-XXX/I-XXX/O) ho·∫∑c clean label (XXX/O)\n",
    "    Return spans: list of (start_token, end_token_exclusive, label)\n",
    "    \"\"\"\n",
    "    spans = []\n",
    "    i = 0\n",
    "    n = min(len(tokens), len(bio_tags))\n",
    "\n",
    "    def norm_tag(t):\n",
    "        if t is None:\n",
    "            return \"O\"\n",
    "        t = t.strip()\n",
    "        return t\n",
    "\n",
    "    while i < n:\n",
    "        t = norm_tag(bio_tags[i])\n",
    "        if t == \"O\":\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        if \"-\" not in t:\n",
    "            label = t\n",
    "            j = i + 1\n",
    "            while j < n and norm_tag(bio_tags[j]) == label:\n",
    "                j += 1\n",
    "            spans.append((i, j, label))\n",
    "            i = j\n",
    "            continue\n",
    "\n",
    "        prefix, label = t.split(\"-\", 1)\n",
    "        if prefix != \"B\":\n",
    "            prefix = \"B\"\n",
    "\n",
    "        j = i + 1\n",
    "        while j < n:\n",
    "            tj = norm_tag(bio_tags[j])\n",
    "            if tj == f\"I-{label}\":\n",
    "                j += 1\n",
    "            else:\n",
    "                break\n",
    "        spans.append((i, j, label))\n",
    "        i = j\n",
    "\n",
    "    return spans\n",
    "\n",
    "\n",
    "def pred_token_tags_to_spans(tokens, clean_tags):\n",
    "    \"\"\"\n",
    "    clean_tags: list[str] ch·ªâ O ho·∫∑c LABEL\n",
    "    Return spans token-level contiguous segments.\n",
    "    \"\"\"\n",
    "    spans = []\n",
    "    n = min(len(tokens), len(clean_tags))\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        lb = clean_tags[i]\n",
    "        if lb == \"O\":\n",
    "            i += 1\n",
    "            continue\n",
    "        j = i + 1\n",
    "        while j < n and clean_tags[j] == lb:\n",
    "            j += 1\n",
    "        spans.append((i, j, lb))\n",
    "        i = j\n",
    "    return spans\n",
    "\n",
    "\n",
    "def spans_to_bio(tokens, spans):\n",
    "    \"\"\"\n",
    "    spans: list (start, end, label) token indices\n",
    "    Return BIO tags list[str]\n",
    "    \"\"\"\n",
    "    tags = [\"O\"] * len(tokens)\n",
    "    for s, e, lb in spans:\n",
    "        if s < 0 or e > len(tokens) or s >= e:\n",
    "            continue\n",
    "        tags[s] = f\"B-{lb}\"\n",
    "        for i in range(s + 1, e):\n",
    "            tags[i] = f\"I-{lb}\"\n",
    "    return tags\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "#  GLiNER inference in batches\n",
    "# =========================================================\n",
    "def gliner_batch_infer(texts, labels, batch_size=32, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Return list[list[span_dict]] same length with texts.\n",
    "    Uses model.inference (non-deprecated).\n",
    "    \"\"\"\n",
    "    all_out = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"üöÄ GLiNER inference\"):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        preds = model.inference(batch, labels=labels, threshold=threshold)\n",
    "        all_out.extend(preds)\n",
    "    return all_out\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# predict -> report -> error analysis\n",
    "# =========================================================\n",
    "all_tokens = [row[\"words\"] for row in test_data]\n",
    "all_texts = [\" \".join(toks) for toks in all_tokens]\n",
    "\n",
    "ID2LABEL_GOLD = None\n",
    "\n",
    "gold_bio = []\n",
    "gold_clean = []\n",
    "for row in test_data:\n",
    "    tags = row[\"tags\"]\n",
    "    if len(tags) > 0 and isinstance(tags[0], str):\n",
    "        gold_bio.append(tags)\n",
    "        gold_clean.append(clean_original_tags(tags, id2label=None))\n",
    "    else:\n",
    "        if ID2LABEL_GOLD is None:\n",
    "            raise ValueError(\"ch∆∞a set ID2LABEL_GOLD\")\n",
    "        tags_str = [ID2LABEL_GOLD[int(x)] for x in tags]\n",
    "        gold_bio.append(tags_str)\n",
    "        gold_clean.append(clean_original_tags(tags_str, id2label=None))\n",
    "\n",
    "batch_preds = gliner_batch_infer(all_texts, TARGET_LABELS, batch_size=BATCH_SIZE, threshold=THRESHOLD)\n",
    "\n",
    "pred_clean = []\n",
    "for toks, pred_spans in zip(all_tokens, batch_preds):\n",
    "    pred_clean.append(spans_to_token_tags(toks, pred_spans, TARGET_LABELS))\n",
    "\n",
    "# -------------------------\n",
    "# TOKEN-LEVEL REPORT\n",
    "# -------------------------\n",
    "y_true_tok = []\n",
    "y_pred_tok = []\n",
    "for tclean, pclean in zip(gold_clean, pred_clean):\n",
    "    L = min(len(tclean), len(pclean))\n",
    "    y_true_tok.extend(tclean[:L])\n",
    "    y_pred_tok.extend(pclean[:L])\n",
    "\n",
    "labels = sorted(list(set(y_true_tok) | set(y_pred_tok)))\n",
    "if \"O\" in labels:\n",
    "    labels.remove(\"O\")\n",
    "\n",
    "print(classification_report(y_true_tok, y_pred_tok, labels=labels, zero_division=0, digits=4))\n",
    "\n",
    "# -------------------------\n",
    "# ENTITY-LEVEL REPORT via seqeval\n",
    "# -------------------------\n",
    "y_true_seq = []\n",
    "y_pred_seq = []\n",
    "for toks, bio_tags, pclean in zip(all_tokens, gold_bio, pred_clean):\n",
    "    gold_spans = bio_to_spans(toks, bio_tags)\n",
    "    gold_bio_norm = spans_to_bio(toks, gold_spans)\n",
    "\n",
    "    pred_spans = pred_token_tags_to_spans(toks, pclean)\n",
    "    pred_bio = spans_to_bio(toks, pred_spans)\n",
    "\n",
    "    y_true_seq.append(gold_bio_norm)\n",
    "    y_pred_seq.append(pred_bio)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ENTITY-LEVEL REPORT\")\n",
    "print(\"=\"*70)\n",
    "print(seqeval_report(y_true_seq, y_pred_seq, digits=4))\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# ERROR ANALYSIS\n",
    "# =========================================================\n",
    "def is_year(tok: str) -> bool:\n",
    "    return bool(re.fullmatch(r\"(19|20)\\d{2}\", tok))\n",
    "\n",
    "def has_disease_variant(tok: str) -> bool:\n",
    "    t = tok.lower()\n",
    "    return (\"covid\" in t) or (\"sars\" in t)\n",
    "\n",
    "def is_time_piece(tok: str) -> bool:\n",
    "    if tok in [\":\", \"h\", \"gi·ªù\", \"s√°ng\", \"chi·ªÅu\", \"t·ªëi\", \"ƒë√™m\"]:\n",
    "        return True\n",
    "    return bool(re.fullmatch(r\"\\d{1,2}\", tok))\n",
    "\n",
    "def guess_error_type(tokens, t_true, t_pred, idx):\n",
    "    tok = tokens[idx]\n",
    "\n",
    "    # FN\n",
    "    if t_true != \"O\" and t_pred == \"O\":\n",
    "        if t_true == \"DATE\" and is_time_piece(tok):\n",
    "            return \"FN_format_DATE\"\n",
    "        if t_true == \"AGE\" and is_year(tok):\n",
    "            return \"FN_format_AGE_year\"\n",
    "        if t_true == \"SYMPTOM_AND_DISEASE\" and has_disease_variant(tok):\n",
    "            return \"FN_normalization_disease_variant\"\n",
    "        if t_true in [\"ORGANIZATION\", \"LOCATION\", \"TRANSPORTATION\"] and len(tok) <= 4:\n",
    "            return \"FN_boundary_or_segmentation\"\n",
    "        return \"FN_other\"\n",
    "\n",
    "    # FP\n",
    "    if t_true == \"O\" and t_pred != \"O\":\n",
    "        if t_pred == \"TRANSPORTATION\" and re.search(r\"\\d\", tok):\n",
    "            return \"FP_id_or_plate_like\"\n",
    "        return \"FP_other\"\n",
    "\n",
    "    # Confusion\n",
    "    if t_true != t_pred:\n",
    "        if (t_true, t_pred) in [\n",
    "            (\"TRANSPORTATION\", \"LOCATION\"),\n",
    "            (\"ORGANIZATION\", \"LOCATION\"),\n",
    "            (\"LOCATION\", \"ORGANIZATION\"),\n",
    "        ]:\n",
    "            return \"Confusion_LOC_ORG_TRANS\"\n",
    "        return \"Confusion_other\"\n",
    "\n",
    "    return \"Correct\"\n",
    "\n",
    "\n",
    "def build_error_analysis(tokens_list, true_clean_list, pred_clean_list, max_examples_per_type=8):\n",
    "    confusion = Counter()\n",
    "    err_type_counter = Counter()\n",
    "    fn_by_label = Counter()\n",
    "    fp_by_label = Counter()\n",
    "    examples = defaultdict(list)\n",
    "\n",
    "    for toks, tclean, pclean in zip(tokens_list, true_clean_list, pred_clean_list):\n",
    "        L = min(len(toks), len(tclean), len(pclean))\n",
    "        for i in range(L):\n",
    "            t = tclean[i]\n",
    "            p = pclean[i]\n",
    "            if t == p:\n",
    "                continue\n",
    "\n",
    "            confusion[(t, p)] += 1\n",
    "\n",
    "            if t != \"O\" and p == \"O\":\n",
    "                fn_by_label[t] += 1\n",
    "            if t == \"O\" and p != \"O\":\n",
    "                fp_by_label[p] += 1\n",
    "\n",
    "            et = guess_error_type(toks, t, p, i)\n",
    "            err_type_counter[et] += 1\n",
    "\n",
    "            if len(examples[et]) < max_examples_per_type:\n",
    "                examples[et].append({\n",
    "                    \"text\": \" \".join(toks),\n",
    "                    \"token\": toks[i],\n",
    "                    \"true\": t,\n",
    "                    \"pred\": p,\n",
    "                    \"pos\": i\n",
    "                })\n",
    "\n",
    "    confusion_df = (\n",
    "        pd.DataFrame([{\"true\": k[0], \"pred\": k[1], \"count\": v} for k, v in confusion.items()])\n",
    "        .sort_values(\"count\", ascending=False)\n",
    "    )\n",
    "    err_type_df = (\n",
    "        pd.DataFrame([{\"error_type\": k, \"count\": v} for k, v in err_type_counter.items()])\n",
    "        .sort_values(\"count\", ascending=False)\n",
    "    )\n",
    "    fn_df = pd.DataFrame(fn_by_label.items(), columns=[\"label\", \"FN_count\"]).sort_values(\"FN_count\", ascending=False)\n",
    "    fp_df = pd.DataFrame(fp_by_label.items(), columns=[\"label\", \"FP_count\"]).sort_values(\"FP_count\", ascending=False)\n",
    "\n",
    "    return confusion_df, err_type_df, fn_df, fp_df, examples\n",
    "\n",
    "\n",
    "confusion_df, err_type_df, fn_df, fp_df, err_examples = build_error_analysis(all_tokens, gold_clean, pred_clean)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ERROR ANALYSIS ‚Äî Top Confusion Pairs\")\n",
    "print(\"=\"*70)\n",
    "print(confusion_df.head(25).to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ERROR ANALYSIS ‚Äî Error Type Distribution\")\n",
    "print(\"=\"*70)\n",
    "print(err_type_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ERROR ANALYSIS ‚Äî False Negatives by Label (missed entities)\")\n",
    "print(\"=\"*70)\n",
    "print(fn_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ERROR ANALYSIS ‚Äî False Positives by Label (spurious entities)\")\n",
    "print(\"=\"*70)\n",
    "print(fp_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval Standard NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-21T09:25:51.082699Z",
     "iopub.status.busy": "2025-12-21T09:25:51.082109Z",
     "iopub.status.idle": "2025-12-21T09:25:52.308631Z",
     "shell.execute_reply": "2025-12-21T09:25:52.307789Z",
     "shell.execute_reply.started": "2025-12-21T09:25:51.082670Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Loading model nqdhocai/vihealthbert-ner-v1 on cuda ...\n",
      "‚úÖ Tokenizer fast = False\n",
      "‚úÖ Loaded test_data: 150 samples\n",
      "üöÄ Evaluating on 150 samples ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loop:   0%|          | 0/150 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Loop: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:00<00:00, 541.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìä ENTITY-LEVEL REPORT (seqeval, BIO)\n",
      "======================================================================\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                AGE     0.9762    0.8542    0.9111        48\n",
      "               DATE     0.9333    0.8750    0.9032        32\n",
      "             GENDER     1.0000    0.9655    0.9825        29\n",
      "                JOB     0.3214    0.1098    0.1636        82\n",
      "           LOCATION     0.6417    0.8000    0.7122       150\n",
      "               NAME     0.0529    0.1538    0.0787        65\n",
      "       ORGANIZATION     0.6579    0.7143    0.6849        35\n",
      "         PATIENT_ID     0.7895    0.3093    0.4444        97\n",
      "SYMPTOM_AND_DISEASE     0.9767    0.8750    0.9231        48\n",
      "     TRANSPORTATION     0.1059    0.1286    0.1161        70\n",
      "\n",
      "          micro avg     0.4831    0.5213    0.5015       656\n",
      "          macro avg     0.6456    0.5785    0.5920       656\n",
      "       weighted avg     0.5879    0.5213    0.5275       656\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üìä TOKEN-LEVEL REPORT (clean labels, O removed)\n",
      "======================================================================\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "                AGE     1.0000    0.7500    0.8571        56\n",
      "               DATE     1.0000    0.8932    0.9436       103\n",
      "             GENDER     1.0000    0.9655    0.9825        29\n",
      "                JOB     1.0000    0.2026    0.3369       232\n",
      "           LOCATION     0.9197    0.8877    0.9034       632\n",
      "               NAME     0.9841    0.8692    0.9231       214\n",
      "       ORGANIZATION     0.7742    0.7059    0.7385       136\n",
      "         PATIENT_ID     0.8158    0.3131    0.4526        99\n",
      "SYMPTOM_AND_DISEASE     0.9896    0.9406    0.9645       101\n",
      "     TRANSPORTATION     0.1882    0.0731    0.1053       219\n",
      "\n",
      "          micro avg     0.8838    0.6557    0.7528      1821\n",
      "          macro avg     0.8672    0.6601    0.7207      1821\n",
      "       weighted avg     0.8452    0.6557    0.7062      1821\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üß© ERROR ANALYSIS ‚Äî Top Confusion Pairs (true ‚Üí pred)\n",
      "======================================================================\n",
      "               true                pred  count\n",
      "     TRANSPORTATION                   O    187\n",
      "                JOB                   O    179\n",
      "         PATIENT_ID      TRANSPORTATION     64\n",
      "           LOCATION                   O     51\n",
      "       ORGANIZATION            LOCATION     33\n",
      "               NAME                   O     26\n",
      "           LOCATION        ORGANIZATION     20\n",
      "                AGE                   O     14\n",
      "     TRANSPORTATION            LOCATION     12\n",
      "               DATE                   O     11\n",
      "       ORGANIZATION                   O      7\n",
      "SYMPTOM_AND_DISEASE                   O      6\n",
      "                JOB        ORGANIZATION      5\n",
      "                  O      TRANSPORTATION      5\n",
      "                  O          PATIENT_ID      4\n",
      "                  O            LOCATION      4\n",
      "     TRANSPORTATION          PATIENT_ID      3\n",
      "         PATIENT_ID                   O      2\n",
      "               NAME        ORGANIZATION      2\n",
      "         PATIENT_ID                NAME      2\n",
      "                  O SYMPTOM_AND_DISEASE      1\n",
      "                JOB                NAME      1\n",
      "     TRANSPORTATION        ORGANIZATION      1\n",
      "             GENDER                   O      1\n",
      "\n",
      "======================================================================\n",
      "üß© ERROR ANALYSIS ‚Äî Error Type Distribution\n",
      "======================================================================\n",
      "                      error_type  count\n",
      "     FN_boundary_or_segmentation    241\n",
      "                        FN_other    225\n",
      "                 Confusion_other     76\n",
      "     Confusion_semantic_neighbor     67\n",
      "                 FP_numeric_like      7\n",
      "                        FP_other      7\n",
      "FN_normalization_disease_variant      6\n",
      "                  FN_format_DATE      6\n",
      "              FN_format_AGE_year      6\n",
      "\n",
      "======================================================================\n",
      "üß© ERROR ANALYSIS ‚Äî False Negatives by Label\n",
      "======================================================================\n",
      "              label  FN_count\n",
      "     TRANSPORTATION       187\n",
      "                JOB       179\n",
      "           LOCATION        51\n",
      "               NAME        26\n",
      "                AGE        14\n",
      "               DATE        11\n",
      "       ORGANIZATION         7\n",
      "SYMPTOM_AND_DISEASE         6\n",
      "         PATIENT_ID         2\n",
      "             GENDER         1\n",
      "\n",
      "======================================================================\n",
      "üß© ERROR ANALYSIS ‚Äî False Positives by Label\n",
      "======================================================================\n",
      "              label  FP_count\n",
      "     TRANSPORTATION         5\n",
      "         PATIENT_ID         4\n",
      "           LOCATION         4\n",
      "SYMPTOM_AND_DISEASE         1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "from seqeval.metrics import classification_report as seqeval_report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# CONFIG\n",
    "# =========================================================\n",
    "MODEL_PATH = \"nqdhocai/vihealthbert-ner-v1\"  \n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 128  \n",
    "\n",
    "# =========================================================\n",
    "# LOAD MODEL + TOKENIZER\n",
    "# =========================================================\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, use_fast=True)\n",
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_PATH).to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "id2label = model.config.id2label\n",
    "label2id = model.config.label2id\n",
    "\n",
    "is_fast = getattr(tokenizer, \"is_fast\", False)\n",
    "\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# normalize gold tags \n",
    "# =========================================================\n",
    "def normalize_true_tags(example_tags, id2label):\n",
    "    if not example_tags:\n",
    "        return []\n",
    "    if isinstance(example_tags[0], str):\n",
    "        return [t.strip() for t in example_tags]\n",
    "    return [id2label[int(t)] for t in example_tags]\n",
    "\n",
    "\n",
    "def bio_to_clean(tags_bio):\n",
    "    out = []\n",
    "    for t in tags_bio:\n",
    "        if t == \"O\" or t is None:\n",
    "            out.append(\"O\")\n",
    "        elif \"-\" in t:\n",
    "            out.append(t.split(\"-\", 1)[1])\n",
    "        else:\n",
    "            out.append(t)\n",
    "    return out\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# ALIGNMENT CORE\n",
    "# =========================================================\n",
    "_word_tokenlen_cache = {}\n",
    "\n",
    "def word_to_subtoken_len(word: str) -> int:\n",
    "    \"\"\"\n",
    "    For slow tokenizer: encode single word (no special tokens) -> length\n",
    "    Cached for speed.\n",
    "    \"\"\"\n",
    "    if word in _word_tokenlen_cache:\n",
    "        return _word_tokenlen_cache[word]\n",
    "    ids = tokenizer(word, add_special_tokens=False).get(\"input_ids\", [])\n",
    "    n = len(ids)\n",
    "    if n == 0:\n",
    "        n = 1\n",
    "    _word_tokenlen_cache[word] = n\n",
    "    return n\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_and_align_batch(batch_words):\n",
    "    \"\"\"\n",
    "    batch_words: list[list[str]]\n",
    "    Return: list[list[str]] predicted BIO tags at word level\n",
    "    Supports:\n",
    "      - fast tokenizer: word_ids()\n",
    "      - slow tokenizer: subtoken length per word\n",
    "    \"\"\"\n",
    "    if is_fast:\n",
    "        enc = tokenizer(\n",
    "            batch_words,\n",
    "            truncation=True,\n",
    "            is_split_into_words=True,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        outputs = model(**enc)\n",
    "        pred_ids = torch.argmax(outputs.logits, dim=-1).detach().cpu().numpy()\n",
    "\n",
    "        batch_preds = []\n",
    "        for bi in range(len(batch_words)):\n",
    "            word_ids = enc.word_ids(batch_index=bi)\n",
    "            prev_wid = None\n",
    "            word_preds = []\n",
    "            for ti, wid in enumerate(word_ids):\n",
    "                if wid is None:\n",
    "                    continue\n",
    "                if wid != prev_wid:\n",
    "                    pid = int(pred_ids[bi][ti])\n",
    "                    word_preds.append(id2label[pid])\n",
    "                    prev_wid = wid\n",
    "            batch_preds.append(word_preds)\n",
    "        return batch_preds\n",
    "\n",
    "\n",
    "    batch_texts = [\" \".join(ws) for ws in batch_words]\n",
    "    enc = tokenizer(\n",
    "        batch_texts,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    outputs = model(**enc)\n",
    "    pred_ids = torch.argmax(outputs.logits, dim=-1).detach().cpu().numpy()\n",
    "\n",
    "    input_ids = enc[\"input_ids\"].detach().cpu().numpy()\n",
    "    special_ids = set()\n",
    "    for k in [\"cls_token_id\", \"sep_token_id\", \"pad_token_id\"]:\n",
    "        v = getattr(tokenizer, k, None)\n",
    "        if v is not None:\n",
    "            special_ids.add(int(v))\n",
    "\n",
    "    batch_preds = []\n",
    "    for bi, words in enumerate(batch_words):\n",
    "        valid_token_positions = []\n",
    "        for ti, tid in enumerate(input_ids[bi]):\n",
    "            if int(tid) in special_ids:\n",
    "                continue\n",
    "            valid_token_positions.append(ti)\n",
    "\n",
    "        lens = [word_to_subtoken_len(w) for w in words]\n",
    "        total_expected = sum(lens)\n",
    "\n",
    "        usable = min(len(valid_token_positions), total_expected)\n",
    "\n",
    "        word_preds = []\n",
    "        cursor = 0\n",
    "        token_cursor = 0\n",
    "        for _, L in enumerate(lens):\n",
    "            if token_cursor >= usable:\n",
    "                break\n",
    "            tok_pos = valid_token_positions[token_cursor]\n",
    "            pid = int(pred_ids[bi][tok_pos])\n",
    "            word_preds.append(id2label[pid])\n",
    "\n",
    "            token_cursor += L\n",
    "            cursor += 1\n",
    "\n",
    "        batch_preds.append(word_preds)\n",
    "\n",
    "    return batch_preds\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# ERROR TAXONOMY\n",
    "# =========================================================\n",
    "def is_year(tok: str) -> bool:\n",
    "    return bool(re.fullmatch(r\"(19|20)\\d{2}\", tok))\n",
    "\n",
    "def has_disease_variant(tok: str) -> bool:\n",
    "    t = tok.lower()\n",
    "    return (\"covid\" in t) or (\"sars\" in t) or (\"sarscov\" in t)\n",
    "\n",
    "def is_time_piece(tok: str) -> bool:\n",
    "    if tok in [\":\", \"h\", \"gi·ªù\", \"s√°ng\", \"chi·ªÅu\", \"t·ªëi\", \"ƒë√™m\", \"ph√∫t\"]:\n",
    "        return True\n",
    "    return bool(re.fullmatch(r\"\\d{1,2}\", tok))\n",
    "\n",
    "def guess_error_type(tokens, true_clean, pred_clean, idx):\n",
    "    tok = tokens[idx]\n",
    "\n",
    "    # FN\n",
    "    if true_clean != \"O\" and pred_clean == \"O\":\n",
    "        if true_clean == \"DATE\" and is_time_piece(tok):\n",
    "            return \"FN_format_DATE\"\n",
    "        if true_clean == \"AGE\" and is_year(tok):\n",
    "            return \"FN_format_AGE_year\"\n",
    "        if true_clean == \"SYMPTOM_AND_DISEASE\" and has_disease_variant(tok):\n",
    "            return \"FN_normalization_disease_variant\"\n",
    "        if true_clean in [\"ORGANIZATION\", \"LOCATION\", \"TRANSPORTATION\", \"NAME\"] and len(tok) <= 4:\n",
    "            return \"FN_boundary_or_segmentation\"\n",
    "        return \"FN_other\"\n",
    "\n",
    "    # FP\n",
    "    if true_clean == \"O\" and pred_clean != \"O\":\n",
    "        if re.search(r\"\\d\", tok) and pred_clean in [\"DATE\", \"TRANSPORTATION\", \"PATIENT_ID\", \"AGE\"]:\n",
    "            return \"FP_numeric_like\"\n",
    "        return \"FP_other\"\n",
    "\n",
    "    # Confusion\n",
    "    if true_clean != pred_clean:\n",
    "        if (true_clean, pred_clean) in [\n",
    "            (\"TRANSPORTATION\", \"LOCATION\"),\n",
    "            (\"ORGANIZATION\", \"LOCATION\"),\n",
    "            (\"LOCATION\", \"ORGANIZATION\"),\n",
    "            (\"NAME\", \"ORGANIZATION\"),\n",
    "            (\"NAME\", \"LOCATION\"),\n",
    "        ]:\n",
    "            return \"Confusion_semantic_neighbor\"\n",
    "        return \"Confusion_other\"\n",
    "\n",
    "    return \"Correct\"\n",
    "\n",
    "\n",
    "def build_error_analysis(tokens_list, true_clean_list, pred_clean_list, max_examples_per_type=8):\n",
    "    confusion = Counter()\n",
    "    err_type_counter = Counter()\n",
    "    fn_by_label = Counter()\n",
    "    fp_by_label = Counter()\n",
    "    examples = defaultdict(list)\n",
    "\n",
    "    for toks, tclean, pclean in zip(tokens_list, true_clean_list, pred_clean_list):\n",
    "        L = min(len(toks), len(tclean), len(pclean))\n",
    "        for i in range(L):\n",
    "            t = tclean[i]\n",
    "            p = pclean[i]\n",
    "            if t == p:\n",
    "                continue\n",
    "\n",
    "            confusion[(t, p)] += 1\n",
    "            if t != \"O\" and p == \"O\":\n",
    "                fn_by_label[t] += 1\n",
    "            if t == \"O\" and p != \"O\":\n",
    "                fp_by_label[p] += 1\n",
    "\n",
    "            et = guess_error_type(toks, t, p, i)\n",
    "            err_type_counter[et] += 1\n",
    "\n",
    "            if len(examples[et]) < max_examples_per_type:\n",
    "                examples[et].append({\n",
    "                    \"text\": \" \".join(toks),\n",
    "                    \"token\": toks[i],\n",
    "                    \"true\": t,\n",
    "                    \"pred\": p,\n",
    "                    \"pos\": i\n",
    "                })\n",
    "\n",
    "    confusion_df = (\n",
    "        pd.DataFrame([{\"true\": k[0], \"pred\": k[1], \"count\": v} for k, v in confusion.items()])\n",
    "        .sort_values(\"count\", ascending=False)\n",
    "    )\n",
    "    err_type_df = (\n",
    "        pd.DataFrame([{\"error_type\": k, \"count\": v} for k, v in err_type_counter.items()])\n",
    "        .sort_values(\"count\", ascending=False)\n",
    "    )\n",
    "    fn_df = pd.DataFrame(fn_by_label.items(), columns=[\"label\", \"FN_count\"]).sort_values(\"FN_count\", ascending=False)\n",
    "    fp_df = pd.DataFrame(fp_by_label.items(), columns=[\"label\", \"FP_count\"]).sort_values(\"FP_count\", ascending=False)\n",
    "\n",
    "    return confusion_df, err_type_df, fn_df, fp_df, examples\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# RUN EVAL\n",
    "# =========================================================\n",
    "y_true_bio_sent, y_pred_bio_sent = [], []\n",
    "tokens_sent, true_clean_sent, pred_clean_sent = [], [], []\n",
    "error_samples = []\n",
    "\n",
    "batch_words, batch_gold = [], []\n",
    "\n",
    "def flush_batch():\n",
    "    global batch_words, batch_gold\n",
    "\n",
    "    if not batch_words:\n",
    "        return\n",
    "\n",
    "    preds_bio = predict_and_align_batch(batch_words)\n",
    "\n",
    "    for words, gold_bio, pred_bio in zip(batch_words, batch_gold, preds_bio):\n",
    "        L = min(len(words), len(gold_bio), len(pred_bio))\n",
    "        words = words[:L]\n",
    "        gold_bio = gold_bio[:L]\n",
    "        pred_bio = pred_bio[:L]\n",
    "\n",
    "        y_true_bio_sent.append(gold_bio)\n",
    "        y_pred_bio_sent.append(pred_bio)\n",
    "\n",
    "        tc = bio_to_clean(gold_bio)\n",
    "        pc = bio_to_clean(pred_bio)\n",
    "\n",
    "        tokens_sent.append(words)\n",
    "        true_clean_sent.append(tc)\n",
    "        pred_clean_sent.append(pc)\n",
    "\n",
    "        mismatches = []\n",
    "        for w, t, p in zip(words, tc, pc):\n",
    "            if t != p:\n",
    "                mismatches.append({\"token\": w, \"true\": t, \"pred\": p})\n",
    "        if mismatches and len(error_samples) < 20:\n",
    "            error_samples.append({\"text\": \" \".join(words), \"errors\": mismatches[:60]})\n",
    "\n",
    "    batch_words, batch_gold = [], []\n",
    "\n",
    "\n",
    "for ex in tqdm(test_data, desc=\"Loop\"):\n",
    "    words = ex[\"words\"]\n",
    "    gold_bio = normalize_true_tags(ex[\"tags\"], id2label)\n",
    "\n",
    "    batch_words.append(words)\n",
    "    batch_gold.append(gold_bio)\n",
    "\n",
    "    if len(batch_words) >= BATCH_SIZE:\n",
    "        flush_batch()\n",
    "\n",
    "flush_batch()\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# REPORTS\n",
    "# =========================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ENTITY-LEVEL REPORT\")\n",
    "print(\"=\"*70)\n",
    "print(seqeval_report(y_true_bio_sent, y_pred_bio_sent, digits=4))\n",
    "\n",
    "y_true_tok = [t for sent in true_clean_sent for t in sent]\n",
    "y_pred_tok = [p for sent in pred_clean_sent for p in sent]\n",
    "labels = sorted(list(set(y_true_tok) | set(y_pred_tok)))\n",
    "if \"O\" in labels:\n",
    "    labels.remove(\"O\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TOKEN-LEVEL REPORT\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(y_true_tok, y_pred_tok, labels=labels, zero_division=0, digits=4))\n",
    "\n",
    "confusion_df, err_type_df, fn_df, fp_df, err_examples = build_error_analysis(\n",
    "    tokens_sent, true_clean_sent, pred_clean_sent\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ERROR ANALYSIS ‚Äî Top Confusion Pairs\")\n",
    "print(\"=\"*70)\n",
    "print(confusion_df.head(25).to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ERROR ANALYSIS ‚Äî Error Type Distribution\")\n",
    "print(\"=\"*70)\n",
    "print(err_type_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ERROR ANALYSIS ‚Äî False Negatives by Label\")\n",
    "print(\"=\"*70)\n",
    "print(fn_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ERROR ANALYSIS ‚Äî False Positives by Label\")\n",
    "print(\"=\"*70)\n",
    "print(fp_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval SLM"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
